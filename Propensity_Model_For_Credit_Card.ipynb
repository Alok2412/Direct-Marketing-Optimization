{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data science: Direct marketing optimization\n",
    "##### Task:\n",
    "Use dummy data to maximize revenue from direct marketing campaigns.\n",
    "##### Data:                   \n",
    "For the analysis, several tables are available:                  \n",
    "1) Social-demographical data (age, gender, tenure in a bank)                 \n",
    "2) Products owned + actual volumes (current account, saving account, mutual funds, overdraft, credit card, consumer loan)      \n",
    "3) Inflow/outflow on C/A, aggregated card turnover (monthly average over past 3 months)          \n",
    "4) For 60 % of clients actual sales + revenues from these are available (training set)                          \n",
    "\n",
    "##### Conditions:     \n",
    "> The bank has capacity to contact only 15 pct. of the clients (cca 100 people) with a marketing offer and each client can be targeted only once.Proposed steps:      \n",
    "1. Create an analytical dataset (both training and targeting sets)                  \n",
    "2. Develop 3 propensity models (consumer loan, credit card, mutual fund) using training data set                \n",
    "3. Optimize targeting clients with the direct marketing offer to maximize the revenue \n",
    "\n",
    "##### Expected result:                                            \n",
    "1) Which clients have higher propensity to buy consumer loan?             \n",
    "2) Which clients have higher propensity to buy credit card?            \n",
    "3) Which clients have higher propensity to buy mutual fund?              \n",
    "4) Which clients are to be targeted with which offer? General description.            \n",
    "5) What would be the expected revenue based on your strategy?             \n",
    "##### The executive summary of the analysis should not be larger than two pages. Attach the technical report, list of clients to be contacted with which offer, data, algorithms and codes used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "from sklearn.impute import KNNImputer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,RandomForestRegressor,AdaBoostRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,roc_curve\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,confusion_matrix,roc_auc_score,f1_score, precision_recall_curve,auc\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import eli5\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data set\n",
    "df_demog = pd.read_excel(\"Data\\Task_Data_Scientist_Dataset.xlsx\",engine='openpyxl',sheet_name='Soc_Dem')\n",
    "df_prod = pd.read_excel(\"Data\\Task_Data_Scientist_Dataset.xlsx\",engine='openpyxl',sheet_name='Products_ActBalance')\n",
    "df_in_out = pd.read_excel(\"Data\\Task_Data_Scientist_Dataset.xlsx\",engine='openpyxl',sheet_name='Inflow_Outflow')\n",
    "df_sales = pd.read_excel(\"Data\\Task_Data_Scientist_Dataset.xlsx\",engine='openpyxl',sheet_name='Sales_Revenues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demog.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_out.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing shape of provided data set\n",
    "print(\"Print shape of Social Demographic data set: \",df_demog.shape)\n",
    "print(\"Print shape of Products Owned and their actual volumes data set: \",df_prod.shape)\n",
    "print(\"print shape of Inflow and Outflow data set: \",df_in_out.shape)\n",
    "print(\"print shape of Train set data set: \",df_sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that their are 28 clients not present in Inflow and Outflow data set. Before merging these data set we have to drop those clients from Social Demographic and Products Owned data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging that two data set having same shape\n",
    "df = pd.merge(df_demog, df_prod, how=\"left\", on=[\"Client\"])\n",
    "df = pd.merge(df, df_in_out, how=\"left\", on=[\"Client\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Print shape of combined data set: \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spliting the data set into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df, df_sales[['Client','Sale_CL','Revenue_CL']], how=\"inner\", on=[\"Client\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Print shape of combined data set: \",df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that most of columns are having very big range and few are having small values so before applying our models to the data set we have to do the scaling of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns which are not required for sale of Consumer loan prediction\n",
    "# columns_sale_cl = ['Count_MF','Count_CC','ActBal_MF','ActBal_CC']\n",
    "columns_sale_cl = ['Count_CL','ActBal_CL']\n",
    "df_train.drop(columns_sale_cl,inplace = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding total number of duplicate values in data set if any\n",
    "print('Total number of duplicate values in the data set is/are: {}'.format(df_train.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking types of the columns in the data set\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values in the data set\n",
    "col = df_train.columns\n",
    "for i in col:\n",
    "    # count number of rows with missing values\n",
    "    n_miss = df_train[[i]].isnull().sum()\n",
    "    perc = n_miss / df_train.shape[0] * 100\n",
    "    print('%s, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that their are lot of missing values in the data set. Before applying any algorithm we have to either impute the values or drop the values.    \n",
    "1) For sex we have two rows missing so I will impute it with U (Unknown) considering that client might not want to reveal their gender.   \n",
    "2) For features from Inflow Outflow data set, having 18 rows missing in all of the feature we will impute it with 0 considering that client is in active in past 3 months.        \n",
    "3) For feature from Product Owned data set we have almost 70-90% data set missing in all features. I think the feature might add value to our model so I will impute this also with 0 considering that client don't avail these features from the bank.    \n",
    "\n",
    "We are not using mean or median imputation because it ignores the feature correlation and will also reduce the variance. Since the data set is very small, smaller variance leads to the narrower confidence interval in the probability distribution. This will lead to bias to our model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing nan values of Sex field with U- Unknown\n",
    "# df_train.dropna(subset = [\"Sex\"], inplace=True)\n",
    "\n",
    "df_train.Sex = df_train.Sex.replace(np.nan,\"U\",regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert Sex from object to numeric type\n",
    "# df_train.Sex.unique()\n",
    "\n",
    "# converting M and F to 1 and 0\n",
    "df_train.Sex = df_train.Sex.replace({'M':1, 'F':0,'U':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing with KNNImputer\n",
    "# col_mean = ['VolumeCred','VolumeCred_CA','TransactionsCred','TransactionsCred_CA','VolumeDeb','VolumeDeb_CA',\n",
    "#            'VolumeDebCash_Card','VolumeDebCashless_Card','VolumeDeb_PaymentOrder','TransactionsDeb','TransactionsDeb_CA'\n",
    "#            ,'TransactionsDebCash_Card','TransactionsDebCashless_Card','TransactionsDeb_PaymentOrder']\n",
    "# k = math.sqrt(df_train.shape[0])\n",
    "# imputer = KNNImputer(n_neighbors=100, weights='uniform', metric='nan_euclidean')\n",
    "# df_train = imputer.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that minimum value for age is zero that means age column is having some erroneous values, we have to analyse age column and see how we can either impute values or if can't impute than drop the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot with tenure of customer with bank\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "sns.distplot(df_train.Age, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking age of customer where age is less than the tenure with the bank\n",
    "df_train.query('Age*12 <=Tenure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that their are 34 rows where age less than the tenure with the bank so we assume that either data in age or tenure is incorrect. But after carefuly considering both the columns we can see that in some case age is even less than 10 years and the client is holding a current account with the bank. So we can say that values in age is wrong.    \n",
    "\n",
    "##### Assumption     \n",
    "1) we assume that to have a bank account with bank client must be atleast of 10 years. Since, even to have a student account the student must be atleast 10 years.      \n",
    "2) To impute the age we will add 10 years with tenure of the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing age with tenure + 120 months \n",
    "df_train.Age = np.where((df_train.Age *12 <= df_train.Tenure),round(df_train.Tenure/12) + 10,df_train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing other values with 0 in the data set\n",
    "df_train.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical analysis of the data set\n",
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still we can see some clients having age less than 10 years so now we will impute these with KNNImputer considering these vales are missing at random.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing with KNNImputer\n",
    "k = math.sqrt(df_train.shape[0])\n",
    "imputer = KNNImputer(n_neighbors=round(k), weights='uniform', metric='nan_euclidean')\n",
    "# df_train.Age = df_train.Age.replace('Age<=10',np.nan,regex=True)\n",
    "df_train.Age = df_train.Age.mask(df_train.Age <= 10)\n",
    "df_train[col] = imputer.fit_transform(df_train.values)\n",
    "# df_train.Age = np.where((df_train.Age *12 <= df_train.Tenure),imputer.fit_transform(df_train.Age.value),df_train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train[col], hue='Sale_CL', corner=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for multicollinearity\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(df_train.corr(),cmap='RdBu',annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some corelation between the features, but we will use different algorithms which can handle these corelation. Other option is to drop the features which are having high corelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot with tenure of customer with bank\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "sns.distplot(df_train.Tenure, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "sns.countplot(df_train.Sale_CL);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their is clear imbalance in the data set we have to handle this also while applying our machine learning algorithm.\n",
    "Two ways by which we can handle this class imbalance problem:    \n",
    "1) By adjusting the class weight while training    \n",
    "2) By over/under sampling of the data set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data set into train and test\n",
    "# deviding the data set into target and predictors\n",
    "X = df_train.copy()\n",
    "X.drop(['Client','Sale_CL','Revenue_CL'],inplace = True, axis = 1)\n",
    "y_sale_cl = df_train.iloc[:,28].values\n",
    "y_revenue_cl = df_train.iloc[:,29].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_sale_cl, test_size=0.2, stratify=y_sale_cl, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Machine learning Models\n",
    "\n",
    "Applying ML classification models for predicting sale of consumer loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be creating a function for model evaluation so that I don't have to write the same code again and again and will be evaluating the model based on different metrics. Based on this evaluation I will decide which algorithm needs parameter tunning and can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model,scale = False, classification = False):\n",
    "    if classification == True:\n",
    "        scoring = [    'precision', \n",
    "                       'recall',\n",
    "                       'f1', \n",
    "                       'accuracy']\n",
    "    else:\n",
    "        scoring = [    \n",
    "                       'neg_mean_squared_error',\n",
    "                       'neg_mean_absolute_error',\n",
    "                       'neg_root_mean_squared_error'\n",
    "                       ]\n",
    "    # Declaring parameters\n",
    "    R_STATE = 1\n",
    "    over = RandomOverSampler(sampling_strategy=0.3,random_state = 1)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5, random_state = 1)\n",
    "    if scale == True :\n",
    "        Steps = [\n",
    "        #             ('i', KNNImputer(n_neighbors=31)),\n",
    "    #                 ('ov',over),\n",
    "    #                 ('un',under),\n",
    "                    ('minmaxscaler',MinMaxScaler(feature_range=(0, 1))),\n",
    "                    ('m', model)\n",
    "                ]\n",
    "    else:\n",
    "        Steps = [\n",
    "            #             ('i', KNNImputer(n_neighbors=31)),\n",
    "        #                 ('ov',over),\n",
    "        #                 ('un',under),\n",
    "                        ('m', model)\n",
    "                    ]\n",
    "    pipeline = Pipeline(steps=Steps)\n",
    "    # evaluate the model\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "    if classification == True:\n",
    "        scores = cross_validate(pipeline, X_train, y_train, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "        # store results\n",
    "        score_df = pd.DataFrame(scores)\n",
    "    else:\n",
    "        scores = cross_validate(pipeline, X_train_reg, y_train_reg, scoring=scoring, cv=10, n_jobs=-1)\n",
    "        # store results\n",
    "        score_df = pd.DataFrame(scores)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation for Ada Boost Algorithm\")\n",
    "model_evaluation(AdaBoostClassifier(),scale = False,classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation XGBoost Algorithm\")\n",
    "model_evaluation(XGBClassifier(),scale = False,classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Random Forest Classifier Algorithm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.990541</td>\n",
       "      <td>0.211409</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.892108</td>\n",
       "      <td>0.126805</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.754839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.199315</td>\n",
       "      <td>0.136008</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.931710</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.690323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.808655</td>\n",
       "      <td>0.133008</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.690323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.936865</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.790055</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.696774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.710632</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.722581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.414206</td>\n",
       "      <td>0.099204</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.394416</td>\n",
       "      <td>0.087005</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.722581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_precision  test_recall   test_f1  test_accuracy\n",
       "0  2.990541    0.211409        0.800000     0.173913  0.285714       0.741935\n",
       "1  1.892108    0.126805        0.785714     0.239130  0.366667       0.754839\n",
       "2  2.199315    0.136008        0.500000     0.130435  0.206897       0.703226\n",
       "3  1.931710    0.156000        0.461538     0.127660  0.200000       0.690323\n",
       "4  1.808655    0.133008        0.466667     0.148936  0.225806       0.690323\n",
       "5  1.936865    0.140400        0.529412     0.195652  0.285714       0.709677\n",
       "6  1.790055    0.124800        0.428571     0.065217  0.113208       0.696774\n",
       "7  1.710632    0.093600        0.571429     0.260870  0.358209       0.722581\n",
       "8  1.414206    0.099204        0.583333     0.148936  0.237288       0.709677\n",
       "9  1.394416    0.087005        0.625000     0.212766  0.317460       0.722581"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model Evaluation Random Forest Classifier Algorithm\")\n",
    "model_evaluation(RandomForestClassifier(),scale = False,classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Logistic Regression Algorithm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.606035</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.651613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.618035</td>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573033</td>\n",
       "      <td>0.058202</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.489028</td>\n",
       "      <td>0.069004</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121404</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.541935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.098803</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.593548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.079203</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.574194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.083401</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.574194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.761290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.625806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_precision  test_recall   test_f1  test_accuracy\n",
       "0  0.606035    0.072603        0.439394     0.630435  0.517857       0.651613\n",
       "1  0.618035    0.052801        0.428571     0.586957  0.495413       0.645161\n",
       "2  0.573033    0.058202        0.405405     0.652174  0.500000       0.612903\n",
       "3  0.489028    0.069004        0.391304     0.574468  0.465517       0.600000\n",
       "4  0.121404    0.046800        0.360465     0.659574  0.466165       0.541935\n",
       "5  0.098803    0.046800        0.404494     0.782609  0.533333       0.593548\n",
       "6  0.079203    0.062400        0.357143     0.543478  0.431034       0.574194\n",
       "7  0.083401    0.046800        0.343750     0.478261  0.400000       0.574194\n",
       "8  0.062400    0.031200        0.592593     0.680851  0.633663       0.761290\n",
       "9  0.062400    0.031200        0.415385     0.574468  0.482143       0.625806"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model Evaluation Logistic Regression Algorithm\")\n",
    "model_evaluation(LogisticRegression(class_weight={0:0.3,1:0.7}),scale = True,classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Naive Bayes Algorithm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147009</td>\n",
       "      <td>0.041201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178010</td>\n",
       "      <td>0.041201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178010</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175010</td>\n",
       "      <td>0.041201</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.683871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.046201</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074401</td>\n",
       "      <td>0.048003</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057201</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.049003</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.043002</td>\n",
       "      <td>0.036002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_precision  test_recall   test_f1  test_accuracy\n",
       "0  0.147009    0.041201        1.000000     0.021739  0.042553       0.709677\n",
       "1  0.178010    0.041201        1.000000     0.021739  0.042553       0.709677\n",
       "2  0.178010    0.056801        0.000000     0.000000  0.000000       0.703226\n",
       "3  0.175010    0.041201        0.250000     0.021277  0.039216       0.683871\n",
       "4  0.046800    0.059801        0.000000     0.000000  0.000000       0.696774\n",
       "5  0.046800    0.046201        0.500000     0.021739  0.041667       0.703226\n",
       "6  0.074401    0.048003        0.666667     0.043478  0.081633       0.709677\n",
       "7  0.057201    0.043003        0.000000     0.000000  0.000000       0.703226\n",
       "8  0.049003    0.032002        1.000000     0.021277  0.041667       0.703226\n",
       "9  0.043002    0.036002        0.000000     0.000000  0.000000       0.696774"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model Evaluation Naive Bayes Algorithm\")\n",
    "model_evaluation(MultinomialNB(),scale = True,classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After validating all the models we can see that AdaBoost and Logistic regression performed well with the given data set so we will perform hyperparameter tunning to see if we can improve the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a parameter grid for cross validation and hyper parameter tuning\n",
    "\n",
    "cv_xgb = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "param_grid_xgb = {'m__max_depth':[6,7,8],\n",
    "              'm__gamma':[0,1],\n",
    "               'm__alpha': [0,1]\n",
    "#               'm__class_weight':[{0:0.1,1:0.9},{0:0.20,1:0.80},'balanced']\n",
    "#               'm__solver':['lbfgs','saga','liblinear']\n",
    "              \n",
    "}\n",
    "model = XGBClassifier()\n",
    "Steps_xgb = [('m', model)]\n",
    "pipeline_xgb = Pipeline(steps = Steps_xgb)\n",
    "grid_search_xgb = GridSearchCV(estimator = pipeline_xgb, param_grid = param_grid_xgb, cv = cv_xgb, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[18:54:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'m__alpha': 0, 'm__gamma': 0, 'm__max_depth': 7}"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.fit(X_train, y_train)\n",
    "grid_search_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = grid_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the values using X_test data set\n",
    "y_pred_xgb = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.90      0.82       136\n",
      "         1.0       0.58      0.31      0.40        58\n",
      "\n",
      "    accuracy                           0.73       194\n",
      "   macro avg       0.67      0.61      0.61       194\n",
      "weighted avg       0.70      0.73      0.70       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression Alogorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating grid for Logistic regression\n",
    "cv_lr = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "param_grid_lr = {'m__max_iter':[40,70,100],\n",
    "              'm__penalty':['l1','l2','elasticnet'],\n",
    "              'm__class_weight':[{0:0.35,1:0.65},{0:0.30,1:0.70},'balanced']\n",
    "#               'm__solver':['lbfgs','saga','liblinear']\n",
    "                }\n",
    "model = LogisticRegression()\n",
    "Steps_lr = [\n",
    "            ('msc',MinMaxScaler(feature_range=(0, 1))),\n",
    "#             ('sc',StandardScaler()),\n",
    "            ('m', model)\n",
    "]\n",
    "pipeline_lr = Pipeline(steps = Steps_lr)\n",
    "grid_search_lr = GridSearchCV(estimator = pipeline_lr, param_grid = param_grid_lr, cv = cv_lr, n_jobs = -1, verbose = 2)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-525-d57e65d2de75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrid_search_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Maynooth\\PythonAnaconda\\envs\\PythonCpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search_lr.fit(X_train, y_train)\n",
    "grid_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = grid_search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the values using X_test data set\n",
    "y_pred_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "# predict probabilities\n",
    "yhat_roc = model_lr.predict_proba(X_test)\n",
    "# retrieve just the probabilities for the positive class\n",
    "pos_probs_roc = yhat_roc[:, 1]\n",
    "# plot no skill roc curve\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='No Sale')\n",
    "# calculate roc curve for model\n",
    "fpr, tpr, _ = roc_curve(y_test, pos_probs_roc)\n",
    "# plot model roc curve\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "roc_auc = roc_auc_score(y_test, pos_probs_roc)\n",
    "print('ROC AUC: %.3f' % roc_auc)\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "\n",
    "# predict probabilities\n",
    "yhat = model_lr.predict_proba(X_test)\n",
    "# retrieve just the probabilities for the positive class\n",
    "pos_probs = yhat[:, 1]\n",
    "sale = len(y_train[y_train==1]) / len(y_train)\n",
    "plt.plot([0, 1], [sale, sale], linestyle='--', label='Sale')\n",
    "# calculate model precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, pos_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('PR AUC: %.3f' % auc_score)\n",
    "# plot the model precision-recall curve\n",
    "plt.plot(recall, precision, marker='.', label='LR')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance code\n",
    "    \n",
    "importance = model_lr.named_steps['m'].coef_[0]\n",
    "cols = list(X_train.columns)\n",
    "\n",
    "# function to color the plot\n",
    "def bar_color(df,color1,color2):\n",
    "    return np.where(importance>0,color1,color2).T\n",
    "\n",
    "# summarize feature importance\n",
    "for col,score in zip(X_train.columns,importance):\n",
    "    print('Feature: %0s, Score: %.5f' % (col,score))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance, color=bar_color(importance,'g','r'))\n",
    "plt.xticks([x for x in range(len(importance))], cols, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the given data set Logistic regression performed well when we changed the class weight. We will use this model for final prediction of sale of consumer loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to disk for sale of consumer loan prediction\n",
    "pickle.dump(model_lr, open('model_lr_sale_cl.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Machine Learning Model\n",
    "\n",
    "Applying Machine Learning model for regression problem and to find the revenue from the sale of consumer loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data set into train and test\n",
    "# deviding the data set into target and predictors for regression problem\n",
    "X_reg = df_train.copy()\n",
    "X_reg.drop(['Client','Revenue_CL'],inplace = True, axis = 1)\n",
    "# y_sale_cl = df_train.iloc[:,26].values\n",
    "y_revenue_cl = df_train.iloc[:,29].values\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_revenue_cl, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(RandomForestRegressor(),scale = False,classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(AdaBoostRegressor(),scale = False,classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn as sklearn\n",
    "# sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross validation results we can see that Linear regression and random forest is performing well so we will do hyper-parameter tunning for this two algorithm and try to improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(Ridge(),scale = True,classification = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out of all models Random forest and Ridge performed well so we will do hyper-parameter tunning for improving the model performance.\n",
    "\n",
    "\n",
    "##### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a parameter grid for cross validation and hyper parameter tuning\n",
    "param_grid_rf = {\n",
    "    'm__max_depth': [80, 90],\n",
    "    'm__min_samples_leaf': [ 4, 5],\n",
    "    'm__min_samples_split': [8, 10],\n",
    "    'm__n_estimators': [50,100,150]\n",
    "}\n",
    "model = RandomForestRegressor()\n",
    "Steps_rf = [ ('m', model)]\n",
    "pipeline_rf = Pipeline(steps = Steps_rf)\n",
    "grid_search_rf = GridSearchCV(estimator = pipeline_rf, param_grid = param_grid_rf, cv = 10, n_jobs = -1, verbose = 2)  \n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rf.fit(X_train_reg, y_train_reg)\n",
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the values using X_test data set\n",
    "y_pred_rf = model_rf.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the metrics for our model performance\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_reg, y_pred_rf))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test_reg, y_pred_rf))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test_reg, y_pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "cols_reg = list(X_train_reg.columns)\n",
    "eli5.explain_weights(model_rf.named_steps['m'], top=15, feature_names=cols_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a parameter grid for cross validation and hyper parameter tuning\n",
    "\n",
    "param_grid_rd = {\n",
    "    'm__alpha': arange(0, 1, 0.01)\n",
    "    \n",
    "}\n",
    "\n",
    "model = Ridge()\n",
    "Steps_rd = [ ('m', model)]\n",
    "pipeline_rd = Pipeline(steps = Steps_rd)\n",
    "grid_search_rd = GridSearchCV(estimator = pipeline_rd, param_grid = param_grid_rd, cv = 10, n_jobs = -1, verbose = 2)  \n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rd.fit(X_train_reg, y_train_reg)\n",
    "grid_search_rd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rd = grid_search_rd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the values using X_test data set\n",
    "y_pred_rd = model_rd.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the metrics for our model performance\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_reg, y_pred_rd))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test_reg, y_pred_rd))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test_reg, y_pred_rd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "eli5.explain_weights(model_rd.named_steps['m'], top=15, feature_names=cols_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to disk for revenue prediction\n",
    "pickle.dump(model_rf, open('model_rf_revenue_cl.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonCpu",
   "language": "python",
   "name": "pythoncpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
